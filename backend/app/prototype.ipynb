{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbb79047",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'backend'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpydantic\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Field\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tools, book_appointment, check_availability\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'backend'"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Annotated, TypedDict, Optional, Literal\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "\n",
    "from pydantic import Field\n",
    "\n",
    "from backend.app.client import tools, book_appointment, check_availability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c1abc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "model = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    api_key=GROQ_API_KEY\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#langgraph state\n",
    "class AgentState(TypedDict):\n",
    "    extracted_data: dict\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b90d790",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Hello, world. It's nice to meet you. Is there something I can help you with, or would you like to chat?\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 39, 'total_tokens': 67, 'completion_time': 0.041796999, 'completion_tokens_details': None, 'prompt_time': 0.009322904, 'prompt_tokens_details': None, 'queue_time': 0.055661215, 'total_time': 0.051119903}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'} id='lc_run--019bd5d0-e9d8-72d2-a955-025ae243f255-0' tool_calls=[] invalid_tool_calls=[] usage_metadata={'input_tokens': 39, 'output_tokens': 28, 'total_tokens': 67}\n"
     ]
    }
   ],
   "source": [
    "res = model.invoke(\"Hello, world!\")\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ff739",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PROMPT = \"\"\" You are a professional appoitment and reporting assistant. \n",
    "Your task is to chat with customers, understand their needs regarding medical appointments,\n",
    "and assist them in booking appointment, checking availablity using the tools provided.\n",
    "\n",
    "If information is missing for tool calling ask the user for missing information.\n",
    "\n",
    "Once the task is done stop the conversation by thanking the user. Don't call any tool after that.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7343bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq.chat_models import ChatGroq\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AnyMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from app.client import tools\n",
    "# from utils.utils import logger\n",
    "from backend.utils import get_today_date\n",
    "\n",
    "\n",
    "PROMPT = \"\"\" You are a professional appoitment and reporting assistant. \n",
    "Your task is to chat with customers, understand their needs regarding medical appointments,\n",
    "and assist them in booking appointment, checking availablity using the tools provided.\n",
    "\n",
    "If information is missing for tool calling ask the user for missing information.\n",
    "\n",
    "Once the task is done stop the conversation by thanking the user. Don't call any tool after that.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    human_input: str\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "\n",
    "def agent_with_tools(state: AgentState):\n",
    "    llm_with_tools = model.bind_tools(tools)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [llm_with_tools.invoke(state[\"messages\"])],\n",
    "    }\n",
    "  \n",
    "def build_prompt(state):\n",
    "    messages = state[\"messages\"].copy()\n",
    "    messages.insert(0, SystemMessage(content=PROMPT.strip()))\n",
    "    return {\"messages\": messages}\n",
    "\n",
    "def should_continue(state: AgentState) -> str:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "        return \"continue\"\n",
    "    return \"end\"\n",
    "\n",
    "def build_agent_graph() -> StateGraph:\n",
    "    graph = StateGraph(AgentState)\n",
    "    \n",
    "    # Streamlined Nodes\n",
    "    graph.add_node(\"agent\", agent_with_tools)\n",
    "    graph.add_node(\"build_prompt\", build_prompt)\n",
    "    graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "    graph.add_edge(START, \"build_prompt\")\n",
    "    graph.add_edge(\"build_prompt\", \"agent\")\n",
    "    graph.add_conditional_edges(\n",
    "        \"agent\", \n",
    "        should_continue, \n",
    "        {\n",
    "            \"continue\": \"tools\", \n",
    "            \"end\": END\n",
    "        }\n",
    "    )\n",
    "    graph.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    # logger.info(\"Agent graph successfully built.\")\n",
    "    return graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b539f8b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_agent_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m r = \u001b[43mbuild_agent_graph\u001b[49m()\n\u001b[32m      2\u001b[39m r\n\u001b[32m      3\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mI would like to book an appointment with Dr. Smith today at 3 PM.\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNameError\u001b[39m: name 'build_agent_graph' is not defined"
     ]
    }
   ],
   "source": [
    "r = build_agent_graph()\n",
    "r\n",
    "question = \"I would like to book an appointment with Dr. Smith today at 3 PM.\"\n",
    "state: AgentState = {\"messages\": [HumanMessage(content=question)]}\n",
    "res = r.invoke(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af0f1807",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'app.client'; 'app' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     14\u001b[39m GROQ_API_KEY = os.getenv(\u001b[33m\"\u001b[39m\u001b[33mGROQ_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m model = ChatGroq(\n\u001b[32m     17\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mllama-3.1-8b-instant\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     18\u001b[39m     api_key=GROQ_API_KEY,\n\u001b[32m     19\u001b[39m     temperature=\u001b[32m0\u001b[39m\n\u001b[32m     20\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tools\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m# from utils.utils import logger\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_today_date\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects jan\\dobbe-ai-assignment\\backend\\app\\app.py:13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdb\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatabase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Appointment, Base\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m date\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m agent_start\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[32m     16\u001b[39m \u001b[38;5;129m@asynccontextmanager\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mlifespan\u001b[39m(app: FastAPI):\n\u001b[32m     18\u001b[39m     \u001b[38;5;66;03m# ‚úÖ startup\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Projects jan\\dobbe-ai-assignment\\backend\\app\\agent.py:12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mapp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mclient\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tools\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# from utils.utils import logger\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_today_date\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'app.client'; 'app' is not a package"
     ]
    }
   ],
   "source": [
    "from langchain_groq.chat_models import ChatGroq\n",
    "from typing import TypedDict, Annotated, Optional\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AnyMessage, ToolMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "model = ChatGroq(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    api_key=GROQ_API_KEY,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "from app.client import tools\n",
    "# from utils.utils import logger\n",
    "from backend.utils import get_today_date\n",
    "\n",
    "PROMPT = \"\"\" \n",
    "### Role\n",
    "You are a highly efficient Medical Appointment and Reporting Assistant. Your goal is to guide users through the scheduling process with clinical precision and professional warmth.\n",
    "\n",
    "### Operational Workflow (Graph Logic)\n",
    "1. Greet: Start by acknowledging the user.\n",
    "2. Context Retrieval: Check the conversation history for Doctor names, Dates, and Times.\n",
    "3. Validation:\n",
    "   - If a specific Doctor/Date/Time is missing, ASK for it.\n",
    "   - For dates/times, assume the current year is 2026. \n",
    "   - FORMAT: Always interpret and pass dates to tools in 'YYYY-MM-DD HH:MM' format.\n",
    "4. Tool Execution: Once all parameters (e.g., doctor_name, appointment_time) are clear, invoke the tool. \n",
    "5. Reporting: Translate the tool's raw output (e.g., success/failure) into a clear message for the user.\n",
    "\n",
    "### Constraints & Guardrails\n",
    "- Data Format: When a user says \"Tomorrow at 10 AM,\" calculate the exact date based on the current date (Tuesday, Jan 20, 2026) and format it as '2026-01-21 10:00'.\n",
    "- One Task at a Time: Do not call multiple tools simultaneously unless necessary.\n",
    "- Finality: After a successful booking or report delivery, thank the user and signal the end of the transaction. Do not suggest further tools unless prompted.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    human_input: str\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "\n",
    "# Since the mcp is asynchronous, we need to make the agent node async as well. [This was the cause of previous errors.]\n",
    "async def agent_with_tools(state: AgentState):\n",
    "    llm_with_tools = model.bind_tools(tools)\n",
    "    response = await llm_with_tools.ainvoke(state[\"messages\"])\n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }\n",
    "\n",
    "def handle_tool_error(state):\n",
    "    \"\"\"\n",
    "    This node intercepts the output from the 'tools' node. \n",
    "    If an error occurred, it formats a message telling the agent what happened.\n",
    "    \"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if \"error\" in last_message.content.lower():\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                ToolMessage(\n",
    "                    tool_call_id=last_message.tool_call_id,\n",
    "                    content=f\"Error: {last_message.content}. Please explain the error in human readable form and dont try to call the tool again.\"\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "    return state\n",
    "  \n",
    "# def build_prompt(state):\n",
    "#     messages = state[\"messages\"].copy()\n",
    "#     messages.insert(0, SystemMessage(content=PROMPT.strip()+ \"\\n\\n### Today's Date: \" + get_today_date()))\n",
    "#     return {\"messages\": messages}\n",
    "\n",
    "# def should_continue(state: AgentState) -> str:\n",
    "#     last_message = state[\"messages\"][-1]\n",
    "#     if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "#         return \"continue\"\n",
    "#     return \"end\"\n",
    "\n",
    "def build_agent_graph() -> StateGraph:\n",
    "    graph = StateGraph(AgentState)\n",
    "    \n",
    "    # Streamlined Nodes\n",
    "    graph.add_node(\"agent\", agent_with_tools)\n",
    "    graph.add_node(\"error_handler\", handle_tool_error)\n",
    "    graph.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "    graph.add_edge(START, \"agent\")\n",
    "    graph.add_conditional_edges(\n",
    "        \"agent\", \n",
    "        tools_condition\n",
    "    )\n",
    "    graph.add_edge(\"tools\", \"error_handler\")\n",
    "    graph.add_edge(\"error_handler\", \"agent\")\n",
    "    # graph.add_edge('agent', END)\n",
    "\n",
    "    # logger.info(\"Agent graph successfully built.\")\n",
    "    return graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ad66a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_agent_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m graph = \u001b[43mbuild_agent_graph\u001b[49m()\n\u001b[32m      2\u001b[39m graph\n",
      "\u001b[31mNameError\u001b[39m: name 'build_agent_graph' is not defined"
     ]
    }
   ],
   "source": [
    "graph = build_agent_graph()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc3059dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage\n",
    "\n",
    "async def run_agent(user_query: str):\n",
    "    # 1. Compile the graph\n",
    "    app = build_agent_graph()\n",
    "    \n",
    "    # 2. Prepare the initial state\n",
    "    # We include the SystemMessage and the HumanMessage here \n",
    "    # so they are the foundation of the 'messages' list.\n",
    "    sys_msg = SystemMessage(content=f\"{PROMPT.strip()}\\n\\n### Today's Date: {get_today_date()}\")\n",
    "    human_msg = HumanMessage(content=user_query)\n",
    "    \n",
    "    inputs = {\"messages\": [sys_msg, human_msg]}\n",
    "    \n",
    "    # 3. Iterate through the stream\n",
    "    # Each 'event' is a dict like: {'node_name': {'messages': [...]}}\n",
    "    print(f\"--- Starting Agent for query: {user_query} ---\")\n",
    "    \n",
    "    async for event in app.astream(inputs, stream_mode=\"updates\"):\n",
    "        for node_name, output in event.items():\n",
    "            print(f\"\\n[Node: {node_name}]\")\n",
    "            \n",
    "            # Access the messages added in this step\n",
    "            if \"messages\" in output:\n",
    "                new_message = output[\"messages\"][-1]\n",
    "                \n",
    "                # Pretty print based on message type\n",
    "                if hasattr(new_message, \"tool_calls\") and new_message.tool_calls:\n",
    "                    for tc in new_message.tool_calls:\n",
    "                        print(f\"  üõ†Ô∏è  Tool Call: {tc['name']}({tc['args']})\")\n",
    "                elif isinstance(new_message, ToolMessage):\n",
    "                    print(f\"  ‚úÖ Tool Result: {new_message.content}\")\n",
    "                else:\n",
    "                    print(f\"  ü§ñ Response: {new_message.content}\")\n",
    "\n",
    "    print(\"\\n--- Interaction Complete ---\")\n",
    "\n",
    "# To run the script\n",
    "def main():\n",
    "    try:\n",
    "        # Check if an event loop is already running (e.g., in Jupyter)\n",
    "        loop = asyncio.get_running_loop()\n",
    "        loop.create_task(run_agent(\"Is Dr. Smith available on Feb 15th?\"))\n",
    "    except RuntimeError:\n",
    "        # No running loop, use asyncio.run\n",
    "        asyncio.run(run_agent(\"Is Dr. Smith available on Feb 15th?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "458f943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d0157b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dobbe-ai-assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
